{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBnSmH167++LSoy1l5Kwz0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshMartinTopno/ReCom/blob/main/RECOM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "MvffzhuAm6FE"
      },
      "outputs": [],
      "source": [
        "# importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the dataset\n",
        "movies = pd.read_csv('ml-1m/movies.dat' , sep = '::', header = None, encoding = 'latin-1' )\n",
        "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, encoding = 'latin-1')\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, encoding = 'latin-1')"
      ],
      "metadata": {
        "id": "rciv0h8ryhl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad8677c-945f-4129-e00c-f3da42fbc582"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-5fc80f0ab83e>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  movies = pd.read_csv('ml-1m/movies.dat' , sep = '::', header = None, encoding = 'latin-1' )\n",
            "<ipython-input-51-5fc80f0ab83e>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, encoding = 'latin-1')\n",
            "<ipython-input-51-5fc80f0ab83e>:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, encoding = 'latin-1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the training set and the test set\n",
        "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t', header = None) # sep and delimiter are the same thing\n",
        "training_set = np.array(training_set, dtype = 'int' )\n",
        "\n",
        "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t', header = None)\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "metadata": {
        "id": "mp1vaCtAz5fz"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the number of users and movies\n",
        "nb_users = int(max(max(training_set[:,0]),max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
      ],
      "metadata": {
        "id": "ecmR-1cT1Nti"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an array where the lines are users and the columns are features\n",
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1, nb_users + 1):\n",
        "   id_movies = data[: , 1][data[: , 0] == id_users]\n",
        "   id_ratings = data[: , 2][data[: , 0] == id_users]\n",
        "   ratings = np.zeros(nb_movies)\n",
        "   ratings[id_movies - 1] = id_ratings\n",
        "   new_data.append(list(ratings))\n",
        "  return new_data\n",
        "\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "metadata": {
        "id": "RKtU98fQ6mQW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting data into tensors\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "metadata": {
        "id": "PkZpBu_mKHfQ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the ratings (1 - 5) into binary rating (0 & 1), where 1 : Liked and 0 : Not Liked\n",
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1 ] = 0 # Torch doesn't support 'or' therefore we need to individually convert all ratings\n",
        "training_set[training_set == 2 ] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1 ] = 0\n",
        "test_set[test_set == 2 ] = 0\n",
        "test_set[test_set >= 3] = 1"
      ],
      "metadata": {
        "id": "zOpa6JsoKkiu"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Architecture of Neural Network (RBM - Restricted Boltazman Machine)\n",
        "class RBM():\n",
        "\n",
        "  def __init__(self, nv, nh): # nv : number of visible nodes, nh : number of hidden nodes\n",
        "  # parameters that will be optimised during the training of the RBM\n",
        "    self.W = torch.randn(nh,nv) # inintialises all weights randomly\n",
        "    self.a = torch.randn(1, nh) # Bias for hidden nodes\n",
        "    self.b = torch.randn(1, nv) # Bias for visible nodes\n",
        "\n",
        "  def sample_h(self, x): # sample the probabilties of the hidden nodes\n",
        "    wx = torch.mm(x, self.W.t())\n",
        "    activation = wx + self.a.expand_as(wx)\n",
        "    p_h_given_v = torch.sigmoid(activation)\n",
        "    return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "\n",
        "  def sample_v(self, y): # sample the probabilties of the visible nodes\n",
        "    wy = torch.mm(y, self.W)\n",
        "    activation = wy + self.b.expand_as(wy)\n",
        "    p_h_given_h = torch.sigmoid(activation)\n",
        "    return p_h_given_h, torch.bernoulli(p_h_given_h)\n",
        "  def train(self, v0, vk, ph0, phk):\n",
        "    self.W += torch.mm(v0.t(), ph0).t() - torch.mm(vk.t(), phk).t()\n",
        "    self.b += torch.sum((v0 - vk), 0)\n",
        "    self.a += torch.sum((ph0 - phk), 0)\n"
      ],
      "metadata": {
        "id": "8aetwJ3QM95g"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nv = len(training_set[0])\n",
        "nh = 100 # our choice (tuneable)\n",
        "batch = 128 # tuneable"
      ],
      "metadata": {
        "id": "9WVVfPtlZUYP"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RBM(nv, nh)"
      ],
      "metadata": {
        "id": "DZJRaDLebpfe"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epoch = 20\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "  train_loss = 0\n",
        "  s = 0.\n",
        "  for id_users in range(0, nb_users - batch, batch):\n",
        "    vk = training_set[id_users : id_users + batch]\n",
        "    v0 = training_set[id_users : id_users + batch]\n",
        "    ph0, _ = model.sample_h(v0)\n",
        "    for k in range(10): # number of steps for random walk in contrastive divegence\n",
        "      _, hk = model.sample_h(vk)  #hidden nodes obtained at kth step\n",
        "      _, vk = model.sample_v(hk)\n",
        "      vk[v0 < 0] = v0[v0 < 0]\n",
        "    phk, _ = model.sample_h(vk)\n",
        "\n",
        "    model.train(v0, vk, ph0, phk)\n",
        "    train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
        "    s += 1.\n",
        "\n",
        "  print(f\"Epoch: {epoch}, Loss: {train_loss/s}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7ptCGgob7Zt",
        "outputId": "4c0c12d2-e15e-4883-c5e4-6ad18f5a1100"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.36805853247642517\n",
            "Epoch: 2, Loss: 0.2535548210144043\n",
            "Epoch: 3, Loss: 0.2352680265903473\n",
            "Epoch: 4, Loss: 0.2469603270292282\n",
            "Epoch: 5, Loss: 0.24955618381500244\n",
            "Epoch: 6, Loss: 0.2467261403799057\n",
            "Epoch: 7, Loss: 0.24906863272190094\n",
            "Epoch: 8, Loss: 0.2470588982105255\n",
            "Epoch: 9, Loss: 0.24538518488407135\n",
            "Epoch: 10, Loss: 0.24696490168571472\n",
            "Epoch: 11, Loss: 0.2431633621454239\n",
            "Epoch: 12, Loss: 0.24498772621154785\n",
            "Epoch: 13, Loss: 0.24479785561561584\n",
            "Epoch: 14, Loss: 0.2453276365995407\n",
            "Epoch: 15, Loss: 0.24555285274982452\n",
            "Epoch: 16, Loss: 0.24400050938129425\n",
            "Epoch: 17, Loss: 0.24807286262512207\n",
            "Epoch: 18, Loss: 0.2414771467447281\n",
            "Epoch: 19, Loss: 0.24636368453502655\n",
            "Epoch: 20, Loss: 0.24385391175746918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EdJNRZfmqRal"
      },
      "execution_count": 60,
      "outputs": []
    }
  ]
}